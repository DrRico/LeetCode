很全面的一个CSDN博客：[点击](https://blog.csdn.net/ThinkWon/article/details/104390612)

## 1、Mysql 中 MyISAM 和 InnoDB 的区别有哪些？

**区别：**

* 1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

* 2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；  

* 3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 

* 4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；    

* 5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

**如何选择：**

* 1. 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM；

* 2. 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。

* 3. 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB；

* 4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用InnoDB，至少不会差。

## 2、Java中equals和==的区别

> 博客一：

- 基本数据类型（也称原始数据类型） ：**byte,short,char,int,long,float,double,boolean**。他们之间的比较，应用双等号（==）,比较的是他们的值。
- 引用数据类型：当他们用（==）进行比较的时候，比较的是他们在内存中的存放地址（确切的说，是**堆内存**地址）。

注：对于第二种类型，除非是同一个new出来的对象，他们的比较后的结果为true，否则比较后结果为false。因为每new一次，都会重新开辟堆内存空间。

- ==：比较的是两个字符串内存地址（堆内存）的数值是否相等，属于数值比较；
- equals()：比较的是两个字符串的内容，属于内容比较。

>  博客二

如果一个变量指向的数据是对象类型的，那么，这时候涉及了两块内存，对象本身占用一块内存（堆内存），变量也占用一块内存，例如Objet obj = new Object();变量obj是一个内存，new Object()是另一个内存，此时，变量obj所对应的内存中存储的数值就是对象占用的那块内存的首地址。

**==：**

**== 比较的是变量(栈)内存中存放的对象的(堆)内存地址，用来判断两个对象的地址是否相同，即是否是指相同一个对象。比较的是真正意义上的指针操作。**

1、比较的是操作符两端的操作数是否是同一个对象。
2、两边的操作数必须是同一类型的（可以是父子类之间）才能编译通过。
3、比较的是地址，如果是具体的阿拉伯数字的比较，值相等则为true，如：
int a=10 与 long b=10L 与 double c=10.0都是相同的（为true），因为他们都指向地址为10的堆。

**equals：**

**equals用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是==的判断。**

　　String s="abce"是一种非常特殊的形式,和new 有本质的区别。它是java中唯一不需要new 就可以产生对象的途径。以String s="abce";形式赋值在java中叫直接量,它是在常量池中而不是象new一样放在压缩堆中。这种形式的字符串，在JVM内部发生字符串拘留，即当声明这样的一个字符串后，JVM会在常量池中先查找有有没有一个值为"abcd"的对象,如果有,就会把它赋给当前引用.即原来那个引用和现在这个引用指点向了同一对象,如果没有,则在常量池中新创建一个"abcd",下一次如果有String s1 = "abcd";又会将s1指向"abcd"这个对象,即以这形式声明的字符串,只要值相等,任何多个引用都指向同一对象.
　　而String s = new String("abcd");和其它任何对象一样.每调用一次就产生一个对象，只要它们调用。

　　也可以这么理解: String str = "hello"; 先在内存中找是不是有"hello"这个对象,如果有，就让str指向那个"hello".如果内存里没有"hello"，就创建一个新的对象保存"hello". String str=new String ("hello") 就是不管内存里是不是已经有"hello"这个对象，都新建一个对象保存"hello"。

equals和==的区别：

equals方法最初是在所有类的基类Object中进行定义的，源码是

```java
public boolean equals(Object obj) {
    return (this == obj);
    }
```

由equals的源码可以看出这里定义的equals与 == 是等效的（Object类中的equals没什么区别），不同的原因就在于有些类（像String、Integer等类）对equals进行了重写，但是没有对equals进行重写的类（比如我们自己写的类）就只能从Object类中继承equals方法，其equals方法与 == 就也是等效的，除非我们在此类中重写equals。

　　对equals重新需要注意五点：

　　1 自反性：对任意引用值X，x.equals(x)的返回值一定为true；
　　2 对称性：对于任何引用值x,y,当且仅当y.equals(x)返回值为true时，x.equals(y)的返回值一定为true；
　　3 传递性：如果x.equals(y)=true, y.equals(z)=true,则x.equals(z)=true ；
　　4 一致性：如果参与比较的对象没任何改变，则对象比较的结果也不应该有任何改变；
　　5 非空性：任何非空的引用值X，x.equals(null)的返回值一定为false 。

**总结来说：**

　　1）对于==，如果作用于基本数据类型的变量，则直接比较其存储的 “值”是否相等；

　　　　如果作用于引用类型的变量，则比较的是所指向的对象的地址

　　2）对于equals方法，注意：equals方法不能作用于基本数据类型的变量

　　　　如果没有对equals方法进行重写，则比较的是引用类型的变量所指向的对象的地址；

　　　　诸如String、Date等类对equals方法进行了重写的话，比较的是所指向的对象的内容。

## 3、接口和抽象类的区别是什么？

> 博客一：

用12个字表示就是：==设计思想不同,使用动机不同==.

抽象类和接口设计的时候,设计思想不同. 设计抽象类是自下而上的过程,因为调用者子类需要某些属性和特有行为,所以调用者继承抽象类 设计接口是自上而下的过程,接口规范某一行为,我某类需要这个行为,调用者实现某接口

开发者使用的时候,使用动机不同. 开发者继承抽象类是为了使用抽象类的属性和行为; 开发者实现接口只是为了使用接口的行为.

**区别总结:**

* 区别一: 抽象类只能单继承,接口能多实现

* 区别二: 抽象类是一个类,可以被任意权限修饰符修饰,静态和非静态属性，final和非final属性，可以有抽象方法和非抽象方法；接口只能被public,final修饰,只能有静态方法,即使没有显示的声明，而且是不可修改的；

* 区别三: 抽象的事物不同:   抽象类是对类的抽象,接口是对行为的抽象抽象类是对整个类抽象,包括属性,行为；接口是对类的行为(局部)进行抽象；

* 区别四: 定义的时候,定义抽象类和接口的思想不同；设计抽象类是自下而上的过程,我子类需要,所以我定义抽象类；设计接口是自上而下的过程,我接口规范某一行为,我某类需要这个行为,我实现某接口；

**核心区别:**

调用者使用动机不同,实现接口是为了使用他规范的某一个行为；继承抽象类是为了使用这个类属性和行为.

**再简单点说:**

我们知道抽象类是从子类中发现公共部分，然后泛化成抽象类，子类继承该父类即可，但是接口不同。实现它的子类可以不存在任何关系，共同之处。例如猫、狗可以抽象成一个动物类抽象类，具备叫的方法。鸟、飞机可以实现飞Fly接口，具备飞的行为，这里我们总不能将鸟、飞机共用一个父类吧！所以说抽象类所体现的是一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在"[is](https://link.zhihu.com/?target=http%3A//www.mydown.com/soft/network/chat/475/444475.shtml)-a" 关系，即父类和派生类在概念本质上应该是相同的。对于接口则不然，并不要求接口的实现者和接口定义在概念本质上是一致的， 仅仅是实现了接口定义的规则而已。

> 博客二：

本身的设计目的就是不同的。

大家讲的都很详细了，我说说我自己的一点浅薄的理解。

我一直认为，工科的知识有个很明显的特点：“以用为本”。在讨论接口和抽象类的区别时，我也想从“用”的角度试着总结一下区别，所以我想到了设计目的。

接口的设计目的，是对类的行为进行约束（更准确的说是一种“有”约束，因为接口不能规定类不可以有什么行为），也就是提供一种机制，可以强制要求不同的类具有相同的行为。它只约束了行为的有无，但不对如何实现行为进行限制。对“接口为何是约束”的理解，我觉得配合泛型食用效果更佳。

而抽象类的设计目的，是代码复用。当不同的类具有某些相同的行为(记为行为集合A)，且其中一部分行为的实现方式一致时（A的非真子集，记为B），可以让这些类都派生于一个抽象类。在这个抽象类中实现了B，避免让所有的子类来实现B，这就达到了代码复用的目的。而A减B的部分，留给各个子类自己实现。正是因为A-B在这里没有实现，所以抽象类不允许实例化出来（否则当调用到A-B时，无法执行）。

> 博客三：

接口和抽象类有什么区别？

你选择使用接口和抽象类的依据是什么？

**接口和抽象类的概念不一样。接口是对动作的抽象，抽象类是对根源的抽象。**

抽象类表示的是，这个对象是什么。

接口表示的是，这个对象能做什么。比如，男人，女人，这两个类（如果是类的话……），他们的抽象类是人。说明，他们都是人。

人可以吃东西，狗也可以吃东西，你可以把“吃东西”定义成一个接口，然后让这些类去实现它.

所以，在高级语言上，一个类只能继承一个类（抽象类）(正如人不可能同时是生物和非生物)，但是可以实现多个接口(吃饭接口、走路接口)。

* 第一点． 接口是抽象类的变体，接口中所有的方法都是抽象的。而抽象类是声明方法的存在而不去实现它的类。
* 第二点． 接口可以多继承，抽象类不行
* 第三点． 接口定义方法，不能实现，而抽象类可以实现部分方法。
* 第四点． 接口中基本数据类型为static 而抽类象不是的。

当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。


抽象类的功能要远超过接口，但是，定义抽象类的代价高。因为高级语言来说（从实际设计上来说也是）每个类只能继承一个类。在这个类中，你必须继承或编写出其所有子类的

所有共性。虽然接口在功能上会弱化许多，但是它只是针对一个动作的描述。而且你可以在一个类中同时实现多个接口。在设计阶段会降低难度的。

## 4、关于面试中经常被问到的JDK8新特性

主要包括：

- 新的语言特性
- 集合对象的修改
- JVM新特性
- HashMap的修改

下面介绍几个面试过程经常被问到的几个新特性

**Lambda表达式、方法引用和默认方法**

**1. Lambda表达式**

Lambda表达式允许把函数作为一个方法的参数。

有几种常见的Lambda表达式：

```text
// 1. 不需要参数,返回值为 5  
() -> 5  
  
// 2. 接收一个参数(数字类型),返回其2倍的值  
x -> 2 * x  
  
// 3. 接受2个参数(数字),并返回他们的差值  
(x, y) -> x – y  
  
// 4. 接收2个int型整数,返回他们的和  
(int x, int y) -> x + y  
  
// 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void)  
(String s) -> System.out.print(s)
```

**2. 方法引用**

JDK8支持了四种方式方法引用

**类型方法引用**引用静态方法ContainingClass::staticMethodName引用特定对象的实例方法containingObject::instanceMethodName引用特定类型的任意对象的实例方法String::compareToIngoreCase引用构造函数ClassName::new

**3. 默认方法和静态方法**

JDK1.8支持在接口中定义默认方法和静态方法， 默认方法可以被接口实现引用。

```text
package defaultmethods;
 
import java.time.*;

public interface TimeClient {
    void setTime(int hour, int minute, int second);
    void setDate(int day, int month, int year);
    void setDateAndTime(int day, int month, int year,
                               int hour, int minute, int second);
    LocalDateTime getLocalDateTime();
    
    // 静态方法
    static ZoneId getZoneId (String zoneString) {
        try {
            return ZoneId.of(zoneString);
        } catch (DateTimeException e) {
            System.err.println("Invalid time zone: " + zoneString +
                "; using default time zone instead.");
            return ZoneId.systemDefault();
        }
    }
    
    // 默认方法
    default ZonedDateTime getZonedDateTime(String zoneString) {
        return ZonedDateTime.of(getLocalDateTime(), getZoneId(zoneString));
    }
}
```

**Colletion的修改**

JDK1.8增强了Collection FrameWork， 支持了lambda， 流和聚合操作。

**改动有两个方面：**

- 支持了lambda， 流和聚合操作
- 改进的类型推断

**JVM新特性**

JDK8在JVM中修改重要有：

- 新增JVM工具：jdeps提供了用于分析类文件的命令行工具。
- 使用metaSpace代替永久区
- 新增NMT(Native Memeory Trace)本地内存跟踪器，参见**[NMT](https://link.zhihu.com/?target=https%3A//docs.oracle.com/javase/8/docs/technotes/guides/vm/nmt-8.html)**

**HashMap变化**

JDK8优化了HashMap的实现， 主要优化点包括：

- 将链表方式修改成链表或者红黑树的形式
- 修改resize的过程，解决JDK7在resize在并发场景下死锁的隐患
- JDK1.7存储使用Entry数组， JDK8使用Node或者TreeNode数组存储

当链表长度大于8是链表的存储结构会被修改成红黑树的形式。

查询效率从O(N)提升到O(logN)。链表长度小于6时，红黑树的方式退化成链表。

JDK7链表插入是从链表头部插入， 在resize的时候会将原来的链表逆序。

JDK8插入从链表尾部插入， 因此在resize的时候仍然保持原来的顺序。



## 5、为什么重写equals时必须重写hashCode方法

> 博客一：

* equals方法与hashCode方法根本就是配套使用的。对于任何一个对象，不论是使用继承自Object的equals方法还是重写equals方法。hashCode方法实际上必须要完成的一件事情就是，==为该equals方法认定为相同的对象返回相同的哈希值==。

* 被String类中的equals方法认定为相等的两个对象拥有两个不同的哈希值（因为他们的地址值不同）。问题分析到这一步，原来的问题“为什么重写equals方法就得重写hashCode方法”已经结束了，它的答案是“==因为必须保证重写后的equals方法认定相同的两个对象拥有相同的哈希值==”。同时我们顺便得出了一个结论：“==hashCode方法的重写原则就是保证equals方法认定为相同的两个对象拥有相同的哈希值==”。

> 博客二：

在每个类中，在重写 equals 方法的时侯，一定要重写 hashcode 方法。如果不这样做，你的类违反了 hashCode的通用约定， 这会阻止它在 HashMap 和 HashSet 这样的集合中正常工作。 根据 Object 规范，以下时具体约定。

1. 当在一个应用程序执行过程中， 如果在 equals 方法比较中没有修改任何信息， 在一个对象上重复调用 hashCode 方法时，它必须始终返回相同的值。从一个应用程序到另一个应用程序的每一次执行返回的值 可以是不一致的。
2. 如果两个对象根据 equals(Object) 方法比较是相等的，那么在两个对象上调用 hashCode 就必须产生的 结果是相同的整数。
3. 如果两个对象根据 equals(Object) 方法比较并不相等，则不要求在每个对象上调用 hashCode 都必须产生不同的结果。但是，程序员应该意识到，为不相等的对象生成不同的结果可能会提高散列表（hash tables） 的性能。

**当无法重写 hashCode 时，所违反第二个关键条款是：相等的对象必须具有相等的哈希码（hash code）**

> 博客三

https://zhuanlan.zhihu.com/p/30321358

### 6、详解HashMap、HashTable、ConcurrentHashMap、HashSet的异同

 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作

---------------------------

> 博客一

- HashTable和HashMap的关系最近，可以认为是HashMap的线程安全版本。我们仍然以Java1.8为例，对HashTable进行分析后发现，其读、写、扩容等操作与HashMap基本一致，但是所有方法都增加了synchronized关键词的修饰，将其变为了同步方法。

**HashTable和HashMap的区别主要有：**

- HashMap是非线程安全的，HashTable是线程安全的。==HashTable实现线程安全的办法是在方法上加同步锁，因此性能更差==。
- HashMap允许插入null值，而HashTable不允许。插入null时，HashTable会抛出NullPointerException。
- HashMap默认初始化数组大小是16，HashTable的默认初始化数组大小是11。HashMap扩容容量变为2n，HashTable扩容时容量变为2n+1，这样元素分布更为均匀。==（扩容机制需要了解）==（[hashMap原理，很好理解的博客](https://zhuanlan.zhihu.com/p/125628540)）

**ConcurrentHashMap**

因为HashTable是基于同步方法实现的线程安全，其效率很低，因此基本很少使用。而HashMap又不支持并发操作。那并发时大家都使用什么呢？就是我们这节所讲的ConcurrentHashMap。

HashTable中的同步方法实际上是对整个HashTable对象加锁，任何操作都会锁住整个对象。这样，当操作变多时，或者HashTable变大时，性能会很差。

而ConcurrentHashMap则采用了另外一种思路，它对整个数组进行了分段。然后对每一个小段进行同步保护，每次加锁只加给一小段数据加锁，那么只要多个操作分布在不同的段上，就可以安全地并发进行。因此提高了性能。

**ConcurrentHashMap源码分析**

ConcurrentHashMap的源码比较复杂，但是与HashMap的思路相似，再次基础上增加了分段（Segment），默认的分段数是16。也就是最多能够支持16个并发，即16个操作分别操作不同的段不会引发冲突和阻塞。而且，该分段数目一经初始化使用后，不允许在修改。

而每个分段内，则更像是一个HashMap。其初始化、扩容等操作都是针对于每个分段内而言的，每个分段内的数组独立扩容，大小可能各不相同，因此，整体而言ConcurrentHashMap是一组聚集在一起的HashMap。

而在进行插入、读取操作时，都是先找到对应的分段，然后在分段内进行操作。分段内的操作就类似于HashMap了，具体参考《HashMap源码详解》，我们不再重复讲解。

**ConcurrentHashMap特点**

- 是线程安全的。并且内部采用分段加锁的策略，其效率比HashTable要高。
- 和HashTable一样，不允许存入null值。

**HashSet**

为什么分析HashMap和相关Map却说道了HashSet？因为HashSet是基于HashMap实现的！

**总结**

- HashTable是线程安全的。原理是在方法上加同步锁，因此性能更差。
- ConcurrentHashMap是线程安全的。并且内部采用分段加锁的策略，其效率比HashTable要高。
- HashSet是基于HashMap实现的。

> 博客二

它们两个在工作原理上几乎是一样的。它们两个的区别主要体现在：对键值对的要求、线程的安全性，迭代器的选择以及速度上。

**shMap和Hashtable的区别**

**1.对键值对的要求**

在进行集合的put(key, value)操作时，对于HashMap来说，它允许key和value的值可以是null。但是，Hashtable则对key和value有要求，不允许key和value为null

**2.线程的安全上**

HashMap是非同步的(synchronized),这也意味着，HashMap在进行插入、删除等操作的时候，是线程不安全的，如果自己没有在程序上对HashMap进行同步的处理，则不能让多个线程共享一个变量。如下图（没有加同步锁）


![img](https://pic1.zhimg.com/80/v2-9009f3448b4be1fb11a83e517e40375c_720w.jpg)



但，Hashtable是线程安全的，这也意味着可以在多个线程的环境上，共享一个变量。不过，需要提出的是，Hashtable是在每个方法前面加一个锁的。如下图



![img](https://pic2.zhimg.com/80/v2-383bc46cc195e9c9408b1962242e9ae1_720w.jpg)



**3.使用迭代器上的区别**

HashMap的迭代器(Iterator)是使用fail-fast机制的(快速失败机制),而Hashtable的迭代器(enumerator)使用的是fail-safe机制(快速安全)。如果不知道fail-fast与fail-safe，建议看看我的另一片文章：

[谈谈fail-fast与fail-safe是什么以及工作机制](https://link.zhihu.com/?target=https%3A//juejin.im/post/5b0d0d34f265da092e390592)

**4.处理速度上的区别**

居然Hashtable在线程安全方面要比HashMap强，那么在其他的方面自然要比它弱。由于Hashtable是线程安全的，同步的，那么在单线程的情况下，它的处理速度是要比HashMap慢的。

但是，就算在多线程环境下，我们也不使用Hashtable,Hashtable的同步锁是加在方法名前面的，意味着它把整个方法的代码都给锁的，所以在处理速度上是特别慢的。所以在多线程的环境下，我们优先使用另一个集合：ConcurrentHashMap，这个集合在工作原理上几乎和前面两个一样，但它是线程安全的，并且它不像Hashtable那样，把整个方法都给加锁，而是在方法里面的关键代码上加同步锁，如图：



![img](https://pic2.zhimg.com/80/v2-e64b8f73339e47e6b487838c8d28b1a5_720w.jpg)



所以，它在处理速度上比Hashtable要快，但比HashMap慢，可以说，ConcurrentHashMap是HashMap和Hashtable的折中方案。

**下面解释一下什么是同步(synchronization):**

假如我们在一个方法前面加了同步锁，那么在多线程的环境下，如果有一个线程1正在执行这个方法里面的代码(也就是所，这个线程获得了同步锁)。那么其他线程则不能进去执行这个方法里面的代码，直到线程1把这个方法里面的代码全部执行完，并且退出这个方法(释放同步锁)，那么其他的线程在获得同步锁之后才能执行这个方法。

## 7、讲一下HashMap为什么不安全

首先HashMap是**线程不安全**的，其主要体现：

- 在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失。

- 在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。

**总结版：HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。**




## 8、线程创建的四种方式

- 继承 Thread 类
- 实现 Runnable 接口
- 通过 ExecutorService 和 Callable\ 实现有返回值的线程
- 基于线程池的execute()，创建临时线程

**继承Thread **

Thread 类实现了 Runnable 接口并定义了操作线程的一些方法，我们可以通过创建类时继承 Thread类来创建一个线程。

具体实现：

（1）创建一个继承Thread的类ThreadDemo

（2）重新run()方法

调用步骤：

（1）创建ThreadDemo 类的对象t1

（2）执行t1.start() 方法来启动线程

```java
//创建线程类
public class ThreadDemo extends Thread {
    //重写run()方法
    @Override
    public void run() {
        for(int i = 0;i<1000;i++) {
            System.out.println("Thread::"+i);
        }
    }
}

/***********************************************************************/
//调用线程

//创建线程对象
ThreadDemo t1 = new ThreadDemo();

//启动线程
t1.start();
```

run()方法中是线程的具体逻辑操作，

start()是一个native本地方法，通过操作系统启动一个线程。

**实现 Runnable 接口**

通过实现Runnable 接口来创建线程类 RThread，但是使用的时候，仍需要创建Thread 对象，把RThread的对象当成参数传入。

具体操作：

（1）实现Runnable 接口创建线程类 RThread

（2）重写run()方法

调用步骤：

（1）创建RThread 类的对象 rThread

（2）创建Thread类对象，并把rThread当成参数传入，相当于对rThread进行了封装。

（3）通过start()方法启动线程

```java
//实现Runnable 接口创建线程类 RThread
public class RThread implements Runnable {
    @Override
    //重写run()方法
    public void run() {
        for(int i = 0;i<1000;i++) {
            System.out.println("Thread::"+i);
        }
    }
}
/***********************************************************************/
//调用线程
//创建RThread 类的对象 rThread
RThread rThread = new RThread();

//创建Thread类对象，并把rThread当成参数传入，相当于对rThread进行了封装。
Thread t2 = new Thread(rThread);

//通过start()方法启动线程
t2.start();
```

**通过 ExecutorService 和 Callable\ 实现有返回值的线程**

我们需要在主线程中开启多个线程去执行一个任务，然后收集各个线程的返回结果并将最终结果进行汇总，这是就需要用到 Callable 接口。

具体步骤：

（1）创建一个类实现Callable接口

（2）重写 call() 方法

调用步骤：

（1）创建线程池

（2）创建接收结果的列表集合

（3）创建线程对象

（4）将线程对象提交到线程池中，并将返回结果接收

（5）将返回结果加入结果集合

（6）关闭线程池

```java
//通过实现Callable接口来创建线程类
public class CThread implements Callable<String> {
    private String name;

    public CThread(String name ) {
        this.name = name;
    }
    //重写call()方法
    @Override
    public String call() throws Exception {
        return name;
    }   
}
/***********************************************************************/
//调用线程

//创建线程池
ExecutorService pool = Executors.newFixedThreadPool(5);

//创建接收结果的列表集合
List<Future> list = new ArrayList<Future>();

for(int i = 0;i<5;i++) {
//创建线程对象
Callable c = new CThread("线程"+i);

//将线程对象提交到线程池中，并将返回结果接收
Future future = pool.submit(c);
System.out.println("线程"+i+"已经加入线程池");

//将返回结果加入集合
list.add(future);
}

//关闭线程池
pool.shutdown();

//打印返回结果
for (Future future : list) {
    try {
        System.out.println(future.get().toString());
    } catch (InterruptedException | ExecutionException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }
}
```

**基于线程池的execute()，创建临时线程**

我们可以利用缓存策略使用线程池来创建线程

具体创建：

（1）创建线程池

（2）调用线程池的execute()方法

（3）采用匿名内部类的方法，创建Runnable对象，并重写run()方法

```java
public class EThread {
    public static void main(String[] args) {
        //创建线程池
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        for(int i = 0;i<10;i++) {
            //调用execute()方法创建线程
            //采用匿名内部类的方法，创建Runnable对象，并重写run()方法
            threadPool.execute(new Runnable() {
                @Override
                public void run() {
                    System.out.println(Thread.currentThread().getName());   
                }
            });
        }
    }
}
```



## 9、为啥使用包装类

**1、对象是对现实世界的模拟**（一切事物皆对象，通过面向对象的方式，将现实世界的事物抽象成对象），在现实中，假设我们去一个系统（数据库）里查询学生李四的年龄，如下图：

![img](https://pic4.zhimg.com/80/v2-07da658f1200d0d52efd708fca0c1557_720w.png)

这时候，录入员还没给李四录入年龄这一项，如果我们用int来声明年龄，大家都知道int是要初始化的，默认情况下为0，0是什么意思，没出生吗？（当然也可以用-1来表示未录入，但总感觉有点怪怪的），如果用Integer来表示，就没这个问题了，为null，就是未录入。

**2、为泛型提供了支持。**

![img](https://pic1.zhimg.com/80/v2-98494a6c35a952d8879436d07d63f41c_720w.png)

**3、提供了丰富的属性和API**

![img](https://pic4.zhimg.com/80/v2-1227bdcc70da00b721f91f6a319466f7_720w.png)

![img](https://pic3.zhimg.com/80/v2-e46267ccdc2af679279ea6bf7f92fc62_720w.png)

注意，比较两个值是否相等请用equals方法，我在[让人疑惑的Java代码 - 知乎专栏](https://zhuanlan.zhihu.com/p/27562748) 一文中已经说得很清楚了，这里就不深入了。

## 10、线程池

优点:

> 说法一

- 线程池中线程的使用率提升，减少对象的创建、销毁；

- 线程池可以控制线程数，有效的提升服务器的使用资源，避免由于资源不足而发生宕机等问题；

> 说法二

- 降低资源消耗

- - 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

- 提高响应速度

- - 当任务到达时，任务可以不需要等到线程创建就能立即执行。

- 提高线程的可管理性

- - 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。但是要做到合理的利用线程池，必须对其原理了如指掌。

- **Executor 框架**

线程池的文章：

[线程池你真不来了解一下吗？](https://zhuanlan.zhihu.com/p/36475103)

[当面试官问线程池时，你应该知道些什么？](https://zhuanlan.zhihu.com/p/62132884)

[Java线程池，你五分钟讲完，而我和面试官聊了半小时](https://zhuanlan.zhihu.com/p/132748927)



![img](https://pic3.zhimg.com/80/v2-1ed8f2a5a379323b7892feca37d504aa_720w.jpg)

- Executor：一个接口，其定义了一个接收 Runnable 对象的方法 executor，其方法签名为 executor(Runnable command),
- ExecutorService：是一个比 Executor 使用更广泛的子类接口，其提供了生命周期管理的方法，以及可跟踪一个或多个异步任务执行状况返回 Future 的方法。
- AbstractExecutorService：ExecutorService 执行方法的默认实现。
- ScheduledExecutorService：一个可定时调度任务的接口。
- ScheduledThreadPoolExecutor：ScheduledExecutorService 的实现，一个可定时调度任务的线程池。
- ThreadPoolExecutor：线程池，可以通过调用 Executors 以下静态工厂方法来创建线程池并返回一个 ExecutorService 对象。

#### 源码解读

线程池的具体实现原理，大致从以下几个方面讲解：

1. 线程池状态
2. 任务的执行
3. 线程池中的线程初始化
4. 任务缓存队列及排队策略
5. 任务拒绝策略
6. 线程池的关闭
7. 线程池容量的动态调整



## 11、线程池执行流程?

默认构造函数

```java
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler
) 
{
    ....
}
```

绝对易懂的构造方法参数讲解



![img](https://pic3.zhimg.com/80/v2-17059b4ced66715e74a332222aecc81a_720w.jpg)

#### 文字描述

corePoolSize，maximumPoolSize，workQueue之间关系。

- 当线程池中线程数小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。
- 当线程池中线程数达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 。
- 当workQueue已满，且maximumPoolSize > corePoolSize时，新提交任务会创建新线程执行任务。
- 当workQueue已满，且提交任务数超过maximumPoolSize，任务由RejectedExecutionHandler处理。
- 当线程池中线程数超过corePoolSize，且超过这部分的空闲时间达到keepAliveTime时，回收这些线程。
- 当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize范围内的线程空闲时间达到keepAliveTime也将回收。

#### 一般流程图



![img](https://pic3.zhimg.com/80/v2-dcf795426ed5fddbfda4cace700e360a_720w.jpg)

从结构角度，更形象的图：



![img](https://pic2.zhimg.com/80/v2-12b52a8cbded0ff41a3aada8a310d995_720w.jpg)

#### 几种典型的工作队列

- **ArrayBlockingQueue**:使用数组实现的有界阻塞队列，特性**先进先出**
- **LinkedBlockingQueue**:使用链表实现的阻塞队列，特性先进先出，可以设置其容量，默认为`Interger.MAX_VALUE`，特性**先进先出**
- **PriorityBlockingQueue**:使用平衡二叉树**堆**，实现的具有**优先级**的无界阻塞队列
- **DelayQueue**:无界阻塞延迟队列，队列中每个元素均有过期时间，当从队列获取元素时，只有过期元素才会出队列。队列头元素是最块要过期的元素。
- **SynchronousQueue**:**一个不存储元素的阻塞队列**，每个插入操作，必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态

#### newFixedThreadPool 流程图

```java
public static ExecutorService newFixedThreadPool(int nThreads){
    return new ThreadPoolExecutor(
            nThreads,   // corePoolSize
            nThreads,   // maximumPoolSize == corePoolSize
            0L,         // 空闲时间限制是 0
            TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue<Runnable>() // 无界阻塞队列
        );
}
```

![img](https://pic4.zhimg.com/80/v2-428c784eacf25c91e56363766f1d4557_720w.jpg)

newCacheThreadPool 流程图

```java
public static ExecutorService newCachedThreadPool(){
    return new ThreadPoolExecutor(
        0,                  // corePoolSoze == 0
        Integer.MAX_VALUE,  // maximumPoolSize 非常大
        60L,                // 空闲判定是60 秒
        TimeUnit.SECONDS,
        // 神奇的无存储空间阻塞队列，每个 put 必须要等待一个 take
        new SynchronousQueue<Runnable>()  
    );
}
```

![img](https://pic1.zhimg.com/80/v2-96d407606eb33b8620c3af0e193a8d94_720w.jpg)

newSingleThreadPool 流程图

```java
public static ExecutorService newSingleThreadExecutor() {
        return 
            new FinalizableDelegatedExecutorService
                (
                    new ThreadPoolExecutor
                        (
                            1,
                            1,
                            0L,
                            TimeUnit.MILLISECONDS,
                            new LinkedBlockingQueue<Runnable>(),
                            threadFactory
                        )
                );
    }
```

可以看到除了多了个 FinalizableDelegatedExecutorService 代理，其初始化和 newFiexdThreadPool 的 nThreads = 1 的时候是一样的。

区别就在于：

- newSingleThreadExecutor返回的ExcutorService在析构函数finalize()处会调用shutdown()
- 如果我们没有对它调用shutdown()，那么可以确保它在被回收时调用shutdown()来终止线程。

使用ThreadFactory，可以改变线程的名称、线程组、优先级、守护进程状态，一般采用默认。

流程图略，请参考 newFiexdThreadPool，这里不再累赘。

#### 最后

还有一个定时任务线程池ScheduledThreadPool

它用来处理延时或定时任务，不常用

## 12、Java中类的加载顺序

一个Java文件从编码完成到最终执行，一般主要包括两个过程

- 编译
- 运行

**编译**，即把我们写好的java文件，通过javac命令编译成字节码，也就是我们常说的.class文件。

**运行**，则是把编译生成的.class文件交给Java虚拟机(JVM)执行。

而我们所说的类加载过程即是指JVM虚拟机把.class文件中类信息加载进内存，并进行解析生成对应的class对象的过程。

举个通俗点的例子来说，JVM在执行某段代码时，遇到了class A， 然而此时内存中并没有class A的相关信息，于是JVM就会到相应的class文件中去寻找class A的类信息，并加载进内存中，这就是我们所说的类加载过程。

由此可见，JVM不是一开始就把所有的类都加载进内存中，而是只有第一次遇到某个需要运行的类时才会加载，且**只加载一次**。

```java
public class test {                         //1.第一步，准备加载类
    public static void main(String[] args) {
        new test();                         //4.第四步，new一个类，但在new之前要处理匿名代码块        
    }
    static int num = 4;                    //2.第二步，静态变量和静态代码块的加载顺序由编写先后决定 
    {
        num += 3;
        System.out.println("b");           //5.第五步，按照顺序加载匿名代码块，代码块中有打印
    }
    int a = 5;                             //6.第六步，按照顺序加载变量
    { // 成员变量第三个
        System.out.println("c");           //7.第七步，按照顺序打印c
    }
    test() { // 类的构造函数，第四个加载
        System.out.println("d");           //8.第八步，最后加载构造函数，完成对象的建立
    }
    static {                              // 3.第三步，静态块，然后执行静态代码块，因为有输出，故打印a
        System.out.println("a");
    }
    static void run()                    // 静态方法，调用的时候才加载// 注意看，e没有加载
    {
        System.out.println("e");
    }
}
```

**总结：**

**如果类还没有被加载：**

- 1、先执行父类的静态代码块和静态变量初始化，并且静态代码块和静态变量的执行顺序只跟代码中出现的顺序有关。
- 2、再执行子类的静态代码块和静态变量初始化。
- 3、执行父类的实例变量初始化
- 4、执行父类的构造函数
- 5、执行子类的实例变量初始化
- 6、执行子类的构造函数
- 7、静态方法与非静态方法只有被调用的时候才会被加载
- 其中，1和2中不需要调用new类实例的时候就就执行了（在类加载到方法区的时候执行的）；其次，就是需要理解子类覆盖父类方法的问题，也就是方法重写与实现多态问题。

**如果类已经被加载：**

- 则==静态代码块==和==静态变量==就不用重复执行，再创建类对象时，只执行与实例相关的变量初始化和构造方法。



**相关扩展知识点：**

- Java虚拟机的基本机构？
- 什么是类加载器？
- 简单谈一下类加载的双亲委托机制？
- 普通Java类的类加载过程和Tomcat的类加载过程是否一样？区别在哪？
- 简单谈一下Java堆的垃圾回收机制？

## 13、abstract和super关键字

**abstract**

- 1、abstract类不能与final,static使用。final修饰方法，子类可以调用，但不能覆盖。
- 2、最好不要有private因为私有和抽象放在一起，子类如果想重写父类的私有方法根本继承不过来，也就无法重写
- 3、抽象类中可以有非抽象方法
- 4、抽象类中可以都是非抽象的，但是抽象方法一定要在类和接口中

**super**

- 1、子类构造函数调用父类构造函数用super
- 2、子类重写父类方法后，若想调用父类中被重写的方法，用super
- 3、未被重写的方法可以直接调用。

## 14、请谈一下Spring MVC的工作原理是怎样的？

**问题一：请问如何在链接里不输入项目名称的情况下启动项目？**

**可以通过修改conf文件夹下的server.xml文件，将该项目的访问路径设为根路径。 这样可以不输入项目名称访问到项目。**



- 参考：SpringMVC是一个基于请求驱动的Web框架，使用了“前端控制器”模型来进行设计，再根据“请求映射规则”分发给相应的页面控制器进行处理。用户请求依次经过的组件为：DispatcherServlet、HandlerMapping、HandlerAdapter，返回一个ModelAndView逻辑视图名、ViewResolver、View

更具体的：

> 版本一

第一步:用户发起请求到前端控制器（DispatcherServlet）

第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找

第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain）

第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler）

第五步：处理器适配器去执行Handler

第六步：Handler执行完给处理器适配器返回ModelAndView

第七步：处理器适配器向前端控制器返回ModelAndView

第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析

第九步：视图解析器像前端控制器返回View

第十步：前端控制器对视图进行渲染

第十一步：前端控制器向用户响应结果

> ​	 版本二：

  1、 用户发送请求至前端控制器DispatcherServlet。

  2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。

  3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。

  4、 DispatcherServlet调用HandlerAdapter处理器适配器。

  5、 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。

  6、 Controller执行完成返回ModelAndView。

  7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。

  8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。

  9、 ViewReslover解析后返回具体View。

  10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。

  11、 DispatcherServlet响应用户。

> 版本三

1.启动web容器将会初始化DispacherServlet同时根据控制器和URL映射关系以及围绕控制器的各类拦截器和消息转换器（处理器执行连）创建HandlerMapping,同时创建处理器执行连调用器HandlerAdapter

2.DispacherServlet拦截用户请求，根据请求信息找到对应的HandlerMapping并由HandlerAdapter调用处理器执行连

3.控制器逻辑结束后将会返回模型和试图给DispacherServlset，servlet根据视图信息查找相应的视图解释器，并将模型中的数据渲染出来

注：上一步中是否要调用视图解释器取决于目标视图是否为逻辑视图，若是将会调用视图解释器，若不是则直接渲染模型数据不需要视图解释器

## 15、请讲一讲你对JVM内存模型的了解？

> 说法一：

- 首先要说一下JVM内存空间分为五部分，分别是：方法区、堆、Java虚拟机栈、本地方法栈、程序计数器

- **方法区**，方法区是被所有线程共享的内存区域，用来存储已被虚拟机加载的类信息、常量、静态变量、JIT（just in time,即时编译技术）编译后的代码等数据。运行时常量池是方法区的一部分，用于存放编译期间生成的各种字面常量和符号引用。主要用来存放类信息、类的静态变量、常量、运行时常量池等，方法区的大小是可以动态扩展的。jdk1.8后**方法区（Method Area）**被元空间(Metaspace)代替。
- **堆**：Heap是OOM故障最主要的发源地，它存储着**几乎所有的实例对象**，堆由**垃圾收集器**自动回收，堆区由各子线程共享使用；通常情况下，它占用的空间是所有内存区域中最大的，但如果无节制地创建大量对象，也容易消耗完所有的空间；堆的内存空间既可以固定大小，也可运行时动态地调整，通过参数-Xms设定初始值、-Xmx设定最大值。主要存放的是数组、类的实例对象、字符串常量池等。
- **Java虚拟机栈**是描述JAVA方法运行过程的内存模型，Java虚拟机栈会为每一个即将执行的方法创建一个叫做“栈帧”的区域，该区域用来存储该方法运行时需要的一些信息，包括：局部变量表、操作数栈、动态链接、方法返回地址等。比如我们方法执行过程中需要创建变量时，就会将局部变量插入到局部变量表中，局部变量的运算、传递等在操作数栈中进行，当方法执行结束后，这个方法对应的栈帧将出栈，并释放内存空间。栈中会发生的两种异常，StackOverFlowError和OutOfMemoryError,StackOverFlowError表示当前线程申请的栈超过了事先定好的栈的最大深度，但内存空间可能还有很多。 而OutOfMemoryError是指当线程申请栈时发现栈已经满了，而且内存也全都用光了。
- **本地方法栈**结构上和Java虚拟机栈一样，只不过Java虚拟机栈是运行Java方法的区域，而本地方法栈是运行本地方法的内存模型。运行本地方法时也会创建栈帧，同样栈帧里也有局部变量表、操作数栈、动态链接和方法返回地址等，在本地方法执行结束后栈帧也会出栈并释放内存资源，也会发生OutOfMemoryError。与 Java 虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。
- **程序计数器**，程序计数器是一个比较小的内存空间，用来记录当前线程正在执行的那一条字节码指令的地址。如果当前线程正在执行的是本地方法，那么此时程序计数器为空。程序计数器有两个作用，1、字节码解释器通过改变程序计数器来一次读取指令，从而实现代码的流程控制，比如我们常见的顺序、循环、选择、异常处理等。2、在多线程的情况下，程序计数器用来记录当前线程执行的位置，当线程切换回来的时候仍然可以知道该线程上次执行到了哪里。**而且程序计数器是唯一一个不会出现OutOfMeroryError的内存区域。**
- **方法区**和**堆**都是线程共享的，在JVM启动时创建，在JVM停止时销毁，而**Java虚拟机栈**、**本地方法栈、程序计数器**是线程私有的，随线程的创建而创建，随线程的结束而死亡。

> 说法二：

![img](https://pic4.zhimg.com/80/v2-354d31865d1fb3362f5a1ca938f9a770_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-c24bc811a35ec0e833971b06cb50eaba_720w.jpg)

> 参考资料三：

- [万万没想到，JVM内存结构的面试题可以问的这么难？](https://zhuanlan.zhihu.com/p/77340044)
  -  1、JVM管理的内存结构是怎样的？
  -  2、不同的虚拟机在实现运行时内存的时候有什么区别？
  -  3、运行时数据区中哪些区域是线程共享的？哪些是独享的？
  -  4、除了JVM运行时内存以外，还有什么区域可以用吗？
  - 5、堆和栈的区别是什么？
  - 6、Java中的数组是存储在堆上还是栈上的？
  - 7、Java中的对象创建有多少种方式？
  - 8、Java中对象创建的过程是怎么样的？
  - 9、Java中的对象一定在堆上分配内存吗？
  - 10、如何获取堆和栈的dump文件？

## 16、HashMap专项

- **1、Hash的概念**：将**任意长度的输入**通过散列算法之后映射成**固定长度的输出**。

- **2、Hash冲突** ：当关键字集合很大时（key的数量很多的时候），关键字值不同的元素可能会映像到哈希表的同一地址上，即K1!=K2，但f(K1)=f(K2),这种现象称为hash冲突， 实际中冲突是**不可避免的**，只能通过**改进哈希函数的性能来减少冲突**。
- **3、你认为好的Hash算法的点应该有哪些？**
  - （1）效率得高，做到长文本也能高效计算出Hash值
  - （2）根据Hash值不能逆推出原文
  - （3）两次输入，如果有一点不同也得保证Hash值是不同的 
  - （4）尽可能要分散，因为在table中slot大部分都处于空闲状态时要尽可能降低Hash冲突 

- **4、HashMap的存储结构长啥样？**：
  - **JDK1.8：**  
    - （1）**数组+链表+红黑树**构成，每个数据单元为一个Node结构，Node结构中有key字段、value字段、next字段、hash字段
    - （2）**next字段**就是发生Hash冲突的时候，当前桶位中的Node与冲突Node连接成一个链表所需要的字段
    - ![在这里插入图片描述](https://uploadfiles.nowcoder.com/files/20200819/202281133_1597798188860_20200803094236589.png)
  - **JDK1.7：**
    - **数组+链表**
    - **解决冲突常用的方法有**拉链法和开放寻址法
      - **开放地址法：**线性开放地址法  平方开放地址法  双散列开放地址法
      - **拉链法：**我们采用链表（jdk1.8之后采用链表+红黑树）的数据结构来去存取发生哈希冲突的输入域的关键字（也就是被哈希函数映射到同一个位桶上的关键字

- **5、如果创建HashMap的时候没有指定HashMap散列表的长度，初始长度为多少？**
- 在JDK 8中，关于默认容量的定义为：static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; //16 ，其故意把16写成**1<<4**，就是提醒开发者，这个地方要是**2的幂**。 
- **（1）为啥用位运算呢？直接写16不好么？**
  - 这样是为了位运算的方便，位与运算比算数计算的效率高了很多，之所以选择16，是为了服务将Key映射到index的算法。 
- **（2）那为啥用16不用别的呢？**
  -  因为在使用不是2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。**这个值既不能太小，也不能太大**。太小了就有可能频繁发生扩容，影响效率，太大了又浪费空间，不划算。 **只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。**  这是为了**实现均匀分布**。

- **6、散列表是New HashMap()的时候创建的，还是什么时候创建的？**：散列表是懒加载机制，只有在第一次put数据的时候才创建（JDK1.8，**JDK1.7是直接加载散列表**）

- **7、负载因子默认是多少，有啥作用？为什么负载因子为0.75？什么时候进行扩容(resize)？**
  - （1）默认为0.75，用于计算扩容阈值
  - （2）loadFactor是负载因子，表示HashMap满的程度，默认值为0.75f，设置成0.75有一个好处，**那就是0.75正好是3/4**，**而capacity又是2的幂**。所以，**两个数的乘积都是整数**。
  - （3）影响扩容主要有两个因素：
    -  **Capacity**：HashMap当前长度。
    -  **LoadFactor**：负载因子，默认值0.75f。 
  - 怎么理解呢，就比如当前的容量大小为100，当你存进第76个的时候，判断发现**大于扩容阈值100\*0.75=75**需要进行resize了，那就进行扩容，但是HashMap的扩容也不是简单的扩大点容量这么简单的。

- **8、扩容？它是怎么扩容的呢？**分为两步 
  -  （1）**扩容**：创建一个新的Entry空数组，长度是**原数组的2倍**。 
  -  （2）**ReHash**：遍历原Entry数组，**把所有的Entry重新Hash到新数组**。 
  - **为什么要重新Hash呢，直接复制过去不香么？**  是因为长度扩大以后，Hash的规则也随之改变。
  - ![在这里插入图片描述](https://uploadfiles.nowcoder.com/files/20200819/202281133_1597798188785_20200803103043516.png)
  - 比如原来长度（Length）是8你位运算出来的值是2 ，新的长度是16你位运算出来的值明显不一样了。

- **9、链表转化为红黑树的条件：**
  - （1）链表长度达到8
  - （2）当前散列表长度达到64
  - 以上两个条件同时满足链表才会转化为红黑树，如果仅仅链表长度达到8，它不会发生链表转红黑树，只会发生一次散列表扩容(resize)

- **10、Node对象里面的hash字段的值是key对象的hashcode的返回值吗？**
  - 不是的，通过key的hashcode的高16位异或低16位得到的新值，这样即使数组table的length比较小的时候，也能保证高低bit都参与到Hash的计算中，避免高16位浪费没起到作用，**尽可能的得到一个均匀分布的hash**。

- **11、为啥我们重写equals方法的时候需要重写hashCode方法呢？你能用HashMap给我举个例子么？**
  - 因为在java中，所有的对象都是继承于Object类。Ojbect类中有两个方法**equals**、**hashCode**，这两个方法都是用来比较两个对象是否相等的。 
  - 在未重写equals方法我们是继承了object的equals方法，**那里的 equals是比较两个对象的内存地址**，显然我们new了2个对象内存地址肯定不一样 
  - 比如发生Hash冲突的时候，我们去get，他就是根据key去hash然后计算出index，找到了2，那我怎么找到具体的”电脑“还是”脑电“呢？ 
  - **equals**！是的，所以如果我们对equals方法进行了重写，建议一定要对hashCode方法重写，**以保证相同的对象返回相同的hash值，不同的对象返回不同的hash值**。

- **12、HashMap的put数据的流程：**

![在这里插入图片描述](https://uploadfiles.nowcoder.com/files/20200819/202281133_1597798189199_20200803112618509.png)

- **13、为什么java8以后链表数据超过8以后，就改成红黑树存储？**
  - 这就涉及到拒接服务攻击了，比如某些人通过找到你的hash碰撞值，来让你的HashMap不断地产生碰撞，那么相同key位置的链表就会不断增长，当你需要对这个HashMap的相应位置进行查询的时候，**就会去循环遍历这个超级大的链表**，性能及其地下。java8使用红黑树来替代超过8个节点数的链表后，查询方式性能得到了很好的提升，**从原来的是O(n)到O(logn)**，容器中节点分布在hash桶中的频率**遵循泊松分布**，桶的长度超过8的概率非常非常小（**约为10万分之一**），所以作者应该是根据概率统计而选择了8作为阀值。

- 14、Hashmap的结构，1.7和1.8有哪些区别？
  - （1）JDK1.7用的是**头插法**，而JDK1.8及之后使用的都是**尾插法**，那么他们为什么要这样做呢？ 因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够**避免出现逆序且链表死循环**的问题。 
  - （2）扩容后数据存储位置的计算方式也不一样：1. 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 & length-1）

- **15、首先HashMap是线程不安全的，其主要体现在哪里？**
  - （1）在jdk1.7中，在多线程环境下，扩容时会造成环**形链或数据丢失**。
  - （2）在jdk1.8中，在多线程环境下，会发生**数据覆盖**的情况。

- **16、红黑树的定义：**
  - 每个节点要么是红色，要么是黑色；      
  - 根节点永远是黑色的；      
  - 所有的叶节点都是是黑色的（注意这里说叶子节点其实是上图中的 NIL 节点）；      
  - 每个红色节点的两个子节点一定都是黑色；      
  - 从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；
    - 性质 3 中指定红黑树的每个叶子节点都是空节点，而且并叶子节点都是黑色。但 Java 实现的红黑树将使用 null 来代表空节点，因此遍历红黑树时将看不到黑色的叶子节点，反而看到每个叶子节点都是红色的。
    - 性质 4 的意思是：从每个根到节点的路径上不会有两个连续的红色节点，但黑色节点是可以连续的。
    - 因此若给定黑色节点的个数 N，最短路径的情况是连续的 N 个黑色，树的高度为 N - 1（此次树高度的基数从0开始）;最长路径的情况为节点红黑相间，树的高度为 2(N - 1) 。
    - 性质 5 是成为红黑树最主要的条件，后序的插入、删除操作都是为了遵守这个规定。红黑树并不是标准平衡二叉树，它以性质 5 作为一种平衡方法，使自己的性能得到了提升。

- BST（二分查找数）存在的主要问题是，数在插入的时候会导致树倾斜，不同的插入顺序会导致树的高度不一样，而树的高度直接的影响了树的查找效率。理想的高度是logN，最坏的情况是所有的节点都在一条斜线上，这样的树的高度为N。  
- 红黑树的定义中的这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的(平衡的复杂度为O(lgN)，简略可以说红黑树也是O(lgN))，严格的所需要数学证明。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。  
- **简单的说，也就是红黑树查找效率比二叉查找树效率高！**

## **17、HashMap源码解读：**

- 1、1.7 中HashMap的数据结构图：
- ![img](http://p3.pstatp.com/large/pgc-image/157fc7d29d0e4a7fb46fe6dbd0fdb40f)
- 2、1.7 中的实现：
- ![img](http://p1.pstatp.com/large/pgc-image/0fbba3baf07e44faaa02e0638c96ce86)
- 这是 HashMap 中比较核心的几个成员变量；看看分别是什么意思？
  1. 初始化桶大小，因为底层是数组，所以这是数组默认的大小。
  2. 桶最大值。
  3. 默认的负载因子（0.75）
  4. table 真正存放数据的数组。
  5. Map 存放数量的大小。
  6. 桶大小，可在初始化时显式指定。
  7. 负载因子，可在初始化时显式指定。
- 重点解释下负载因子：由于给定的 HashMap 的容量大小是固定的，比如默认初始化：给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。因此通常建议能提前预估 HashMap 的大小最好，尽量的减少扩容带来的性能损耗。
-  根据代码可以看到其实真正存放数据的是`transient Entry<K,V>[] table = (Entry<K,V>[]) EMPTY_TABLE;`这个数组，那么它又是如何定义的呢？

- ![img](http://p9.pstatp.com/large/pgc-image/564a35bdfff441158b44b64578df0a1e)

- Entry 是 HashMap 中的一个内部类，从他的成员变量很容易看出：
  - key 就是写入时的键。
  - value 自然就是值。
  - 开始的时候就提到 HashMap 是由数组和链表组成，所以这个 next 就是用于实现链表结构。
  - hash 存放的是当前 key 的 hashcode。

- 3、1.7中put 方法:
  - 判断当前数组是否需要初始化。
  - 如果 key 为空，则 put 一个空值进去。
  - 根据 key 计算出 hashcode。
  - 根据计算出的 hashcode 定位出所在桶。
  - 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。
  - 如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。

- 4、1.7中get 方法：
  - 首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。
  - 判断该位置是否为链表。
  - 不是链表就根据 key、key 的 hashcode 是否相等来返回值。
  - 为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。
  - 啥都没取到就直接返回 null 。

- 5、Base 1.8后：不知道 1.7 的实现大家看出需要优化的点没有？其实一个很明显的地方就是：==当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)。==因此 1.8 中重点优化了这个查询效率。1.8 HashMap 结构图：
- ![img](http://p1.pstatp.com/large/pgc-image/3acc46dbd78345aeab33fb49a3fa12b7)

- 先来看看几个核心的成员变量：

  - ```java
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16 
    ```

  - 和 1.7 大体上都差不多，还是有几个重要的区别：

    - TREEIFY_THRESHOLD 用于判断是否需要将链表转换为红黑树的阈值。
    - HashEntry 修改为 Node。

- Node 的核心组成其实也是和 1.7 中的 HashEntry 一样，存放的都是 key value hashcode next 等数据。再来看看核心方法。

- **6、1.8中put 方法：**
  - ![img](http://p1.pstatp.com/large/pgc-image/e6acc1e2eb704433bfbed65be1ffac12)
  - 看似要比 1.7 的复杂，我们一步步拆解：
    1. 判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。
    2. 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。
    3. 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。
    4. 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。
    5. 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。
    6. 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。
    7. 如果在遍历过程中找到 key 相同时直接退出遍历。
    8. 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。
    9. 最后判断是否需要进行扩容。

- **7、1.8中get 方法：**

```java
public V get(Object key)
{
    Node < K, V > e;
    return(e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node < K, V > getNode(int hash, Object key)
    {
        Node < K, V > [] tab;
        Node < K, V > first, e;
        int n;
        K k;
        if((tab = table) != null && (n = tab.length) > 0 && (first = tab[(n - 1) & hash]) != null)
        {
            if(first.hash == hash && // always check first node ((k = first.key) == key || (key != null && key.equals(k)))) return first; 
                if((e = first.next) != null)
                {
                    if(first instanceof TreeNode) return((TreeNode < K, V > ) first).getTreeNode(hash, key);
                    do {
                        if(e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e;
                    } while ((e = e.next) != null);
                }
            }
            return null;
        }
```

- get 方法看起来就要简单许多了。
  1. 首先将 key hash 之后取得所定位的桶。
  2. 如果桶为空则直接返回 null 。
  3. 否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。
  4. 如果第一个不匹配，则判断它的下一个是红黑树还是链表。
  5. 红黑树就按照树的查找方式返回值。
  6. 不然就按照链表的方式遍历匹配返回值。

- 从这两个核心方法（get/put）可以看出 1.8 中对大链表做了优化，修改为红黑树之后查询效率直接提高到了 O(logn)。但是 HashMap 原有的问题也都存在，比如在并发场景下使用时容易出现死循环。

```java
final HashMap < String, String > map = new HashMap < String, String > ();
for(int i = 0; i < 1000; i++)
{
    new Thread(new Runnable()
    {
      	@Override public void run()
        {
            map.put(UUID.randomUUID().toString(), "");
        }
    }).start();
}
```

- 但是为什么呢？简单分析下。看过上文的还记得在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。如下图：

![img](http://p1.pstatp.com/large/pgc-image/9b129c6c215d479796c1d3fc114cb5cb)

- 8、**遍历方式：**还有一个值得注意的是 HashMap 的遍历方式，通常有以下几种：

```java
Iterator < Map.Entry < String, Integer >> entryIterator = map.entrySet().iterator();
while(entryIterator.hasNext())
{
    Map.Entry < String, Integer > next = entryIterator.next();
    System.out.println("key=" + next.getKey() + " value=" + next.getValue());
}
```

-----

```java
Iterator < String > iterator = map.keySet().iterator();
while(iterator.hasNext())
{
    String key = iterator.next();
    System.out.println("key=" + key + " value=" + map.get(key));
}
```

- 强烈建议使用第一种 EntrySet 进行遍历。第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低。



- **9、 简单总结下 HashMap：无论是 1.7或1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至出现死循环导致系统不可用。**故 JDK 推出了专项专用的==**ConcurrentHashMap**== ，该类位于 **java.util.concurrent** 包下，专门用于解决并发问题。

> 坚持看到这里的朋友算是已经把 ConcurrentHashMap 的基础已经打牢了，下面正式开始分析。

---

## 18、ConcurrentHashMap

> ConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。

- 1、Base 1.7：先来看看 1.7 的实现，下面是他的结构图：

  ![img](http://p3.pstatp.com/large/pgc-image/553a0450230a4568a40cd8b163507b43)

- 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。它的核心成员变量：

```java
/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */
final Segment < K, V > [] segments;
transient Set < K > keySet;
transient Set < Map.Entry < K, V >> entrySet;
```

- Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下：

```java
static final class Segment < K, V > extends ReentrantLock implements Serializable
{
    private static final long serialVersionUID = 2249069246763182397 L; // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶
    transient volatile HashEntry < K, V > [] table;
    transient int count;
    transient int modCount;
    transient int threshold;
    final float loadFactor;
}
```

- 看看其中 HashEntry 的组成：
- ![img](http://p3.pstatp.com/large/pgc-image/a01875018edc47bc9c22db42c10a5109)

- 和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。
- 原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。下面也来看看核心的 put get 方法。

- **2、put 方法：**

```java
public V put(K key, V value)
{
    Segment < K, V > s;
    if(value == null) throw new NullPointerException();
    int hash = hash(key);
    int j = (hash >>> segmentShift) & segmentMask;
    if((s = (Segment < K, V > ) UNSAFE.getObject //nonvolatile; 
        recheck(segments, (j << SSHIFT) + SBASE)) == null) 
        // in ensureSegment s = ensureSegment(j);
        return s.put(key, hash, value, false);
}
```

- ​	首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent)
{
    HashEntry < K, V > node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;
    try
    {
        HashEntry < K, V > [] tab = table;
        int index = (tab.length - 1) & hash;
        HashEntry < K, V > first = entryAt(tab, index);
        for(HashEntry < K, V > e = first;;)
        {
            if(e != null)
            {
                K k;
                if((k = e.key) == key || (e.hash == hash && key.equals(k)))
                {
                    oldValue = e.value;
                    if(!onlyIfAbsent)
                    {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            else
            {
                if(node != null) node.setNext(first);
                else node = new HashEntry < K, V > (hash, key, value, first);
                int c = count + 1;
                if(c > threshold && tab.length < MAXIMUM_CAPACITY) rehash(node);
                else setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    }
    finally
    {
        unlock();
    }
    return oldValue;
}
```

- 虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。

- 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。

![img](http://p3.pstatp.com/large/pgc-image/bc0159d7e7c34147b1a59ac8f4fa0425)

1. 尝试自旋获取锁。
2. 如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。

![img](http://p3.pstatp.com/large/pgc-image/3fae927f02d54cd5ada7dbcca45a0d85)

- 再结合图看看 put 的流程。
  1. 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。
  2. 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。
  3. 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。
  4. 最后会解除在 1 中所获取当前 Segment 的锁。

- **3、get 方法**

```java
public V get(Object key)
{
    Segment < K, V > s; // manually integrate access methods to reduce overhead 
    HashEntry < K, V > [] tab;
    int h = hash(key);
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    if((s = (Segment < K, V > ) UNSAFE.getObjectVolatile(segments, u)) != null && (tab = s.table) != null)
    {
        for(HashEntry < K, V > e = (HashEntry < K, V > ) UNSAFE.getObjectVolatile(tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE); e != null; e = e.next)
        {
            K k;
            if((k = e.key) == key || (e.hash == h && key.equals(k))) return e.value;
        }
    }
    return null;
}
```

- get 逻辑比较简单：只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。ConcurrentHashMap 的 get 方法是非常高效的，**因为整个过程都不需要加锁**。



- 4、**Base 1.8：**1.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。

> 那就是查询遍历链表效率太低。

- 因此 1.8 做了一些数据结构上的调整。首先来看下底层的组成结构：

![img](http://p1.pstatp.com/large/pgc-image/1175055614d148e8b09800e88b281553)

- 看起来是不是和 1.8 HashMap 结构类似？其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。

![img](http://p3.pstatp.com/large/pgc-image/a9e67ae236974a4bb98eaf65a30d21cb)

- 也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。其中的 val next 都用了 volatile 修饰，保证了可见性。

- **5、1.8的put 方法：重点来看看 put 函数：**
- ![img](http://p1.pstatp.com/large/pgc-image/15e5dd4d33b24c18bd43dc07dfabe3f7)
  1. 根据 key 计算出 hashcode 。
  2. 判断是否需要进行初始化。
  3. f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
  4. 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。
  5. 如果都不满足，则利用 synchronized 锁写入数据。
  6. 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。
- **6、1.8中get 方法：**
- ![img](http://p3.pstatp.com/large/pgc-image/4021a2fb02cb4e6088d5883ed1a8a4e8)
  - 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。
  - 如果是红黑树那就按照树的方式获取值。
  - 就不满足那就按照链表的方式遍历获取值。

> 1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。

**7、总结**

- 看完了整个 HashMap 和 ConcurrentHashMap 在 1.7 和 1.8 中不同的实现方式相信大家对他们的理解应该会更加到位。

其实这块也是面试的重点内容，通常的套路是：

1. **谈谈你理解的 HashMap，讲讲其中的 get put 过程。**
2. **1.8 做了什么优化？**
3. **是线程安全的嘛？**
4. **不安全会导致哪些问题？**
5. **如何解决？有没有线程安全的并发容器？**
6. **ConcurrentHashMap 是如何实现的？ 1.7、1.8 实现有何不同？为什么这么做？**

这一串问题相信大家仔细看完都能怼回面试官。

除了面试会问到之外平时的应用其实也蛮多。

## 19、类加载机制（图片版）

### 1、类的加载过程：

![img](https://upload-images.jianshu.io/upload_images/13898040-fc87f32ebd9cd850.png?imageMogr2/auto-orient/strip|imageView2/2/w/458/format/webp)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820173812607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

五部曲（三部曲）：加载---->链接（验证----->准备----->解析）----->初始化

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820173838625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820173915718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

### 2、类加载器的作用

虚拟机设计团队把加载动作放到JVM 外部实现，以便让应用程序决定如何获取所需的类，JVM
提供了3 种类加载器：

- 启动类加载器(Bootstrap ClassLoader)：负责加载JAVA_HOME\lib 目录中的，或通过
  -Xbootclasspath 参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。

- 扩展类加载器(Extension ClassLoader)：负责加载JAVA_HOME\lib\ext 目录中的，或通过
  java.ext.dirs 系统变量指定路径中的类库。

- 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。

  

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820174033691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820174108377.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820174135606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY29fUmljb18=,size_16,color_FFFFFF,t_70#pic_center)

## 20、类加载机制（文字版）

> 首先，认识类加载机制，然后，详细介绍类加载的过程。最后，介绍了类加载器，还有双亲委派原则。

**一、什么是类的加载**

​		在介绍类的加载机制之前，先来看看，类的加载机制在整个java程序运行期间处于一个什么环节，下面使用一张图来表示：

![img](https://pics0.baidu.com/feed/37d12f2eb9389b50828b0dfd61271ed9e6116ec5.jpeg?token=d636526e80bfc081f77f2572a772fe0f&s=B1B25D32819E4DCA56C9C0CE020090B2)

​		从上图可以看，java文件通过编译器变成了.class文件，接下来类加载器又将这些.class文件加载到JVM中。其中**类装载器**的**作用**其实就是类的加载。今天我们要讨论的就是这个环节。有了这个印象之后我们再来看**类的加载**的概念：

> ​		其实可以一句话来解释：
>
> ​		类的加载指的是将**类的.class文件**中的二进制数据**读入到内存中**，将其放在运行时数据区的方法区内，然后在**堆区创建一个 java.lang.Class对象**，用来封装类在**方法区**内的数据结构。

​		到现在为止，我们基本上对类加载机制处于整个程序运行的环节位置，还有类加载机制的概念有了基本的印象。在类加载.class文件之前，还有两个问题需要我们去弄清楚：

- 1、在什么时候才会启动类加载器？

  ​		其实，类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（**LinkageError**错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。

- 2、从哪个地方去加载.class文件

  ​		在这里进行一个简单的分类。例举了5个来源

  - （1）本地磁盘
  - （2）网上加载.class文件（Applet）
  - （3）从数据库中
  - （4）压缩文件中（ZAR，jar等）
  - （5）从其他文件生成的（JSP应用）

  有了这个认识之后，下面就开始讲讲，类加载机制了。首先看的就是类加载机制的过程。

**二、类加载的过程**

​		类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。它们的顺序如下图所示：

![img](https://pics7.baidu.com/feed/eaf81a4c510fd9f9a14099a4c13f2f2e2934a444.jpeg?token=e2880e42daad3c92998175106108d106&s=3E2C702394A8C1011CF511CE0100E0B1)

​		其中**类加载的过程包括了加载、验证、准备、解析、初始化五个阶段**。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始。另外注意这里的几个阶段是按顺序**开始**，而不是按顺序**进行**或**完成**，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。

​		下面就一个一个去分析一下这几个过程。

**1、加载**

​		”加载“是”类加机制”的第一个过程，在加载阶段，虚拟机主要完成三件事：

（1）通过一个类的**全限定名**来获取其定义的**二进制字节流**

（2）将这个字节流所代表的的**静态存储结构**转化为**方法区**的运行时**数据结构**

（3）在**堆**中生成一个代表这个类的**Class对象**，作为方法区中这些数据的**访问入口**。

​		相对于类加载的其他阶段而言，加载阶段是可控性最强的阶段，因为程序员可以使用系统的类加载器加载，还可以使用自己的类加载器加载。我们在最后一部分会详细介绍这个类加载器。在这里我们只需要知道类加载器的作用就是上面虚拟机需要完成的三件事，仅此而已就好了。

**2、验证**

​		验证的主要作用就是确保被加载的类的正确性。也是连接阶段的第一步。说白了也就是我们加载好的**.class文件**不能对我们的虚拟机有危害，所以先检测验证一下。他主要是完成**四个阶段的验证**：

- （1）**文件格式的验证**：验证.class文件字节流是否符合class文件的格式的规范，并且能够被当前版本的虚拟机处理。这里面主要对魔数、主版本号、常量池等等的校验（魔数、主版本号都是.class文件里面包含的数据信息、在这里可以不用理解）。
- （2）**元数据验证**：主要是对字节码描述的信息进行语义分析，以保证其描述的信息符合java语言规范的要求，比如说验证这个类是不是有父类，类中的字段方法是不是和父类冲突等等。
- （3）**字节码验证**：这是整个验证过程最复杂的阶段，主要是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。在元数据验证阶段对数据类型做出验证后，这个阶段主要对类的方法做出分析，保证类的方法在运行时不会做出威海虚拟机安全的事。
- （4）**符号引用验证**：它是验证的最后一个阶段，发生在虚拟机将符号引用转化为直接引用的时候。主要是对类自身以外的信息进行校验。目的是确保解析动作能够完成。

​         对整个类加载机制而言，验证阶段是一个很重要但是非必需的阶段，如果我们的代码能够确保没有问题，那么我们就没有必要去验证，毕竟验证需要花费一定的的时间。当然我们可以使用-Xverfity:none来关闭大部分的验证。

**3、准备**

​		**准备阶段主要为类变量分配内存并设置初始值**。这些内存都在方法区分配。在这个阶段我们只需要注意两点就好了，也就是**类变量**和**初始值**两个关键词：

- （1）**类变量（static）会分配内存**，但是**实例变量不会**，实例变量主要==随着对象的实例化一块分配到java堆==中，
- （2）这里的初始值指的是**数据类型默认值**，而不是代码中被显示赋予的值。比如public static int value = 1; //在这里准备阶段过后的value值为0，而不是1。赋值为1的动作在初始化阶段。当然还有其他的默认值。

![img](https://pics2.baidu.com/feed/962bd40735fae6cdf616ed21e7a1f42043a70fe3.png?token=531148998856e5d92d0b437d9f9131b2&s=1AAA7423131A4DC8585DB1CB0300C0B1)

​		注意，在上面value是被static所修饰的准备阶段之后是0，但是如果同时被==**final和static修饰**==准备阶段之后就是1了。我们可以理解为static final在编译器就将结果放入调用它的类的常量池中了。

**4、解析**

​		**解析阶段主要是虚拟机将常量池中的==符号引用==转化为==直接引用==的过程**。什么是符号应用和直接引用呢？

- 符号引用：以一组符号来描述所引用的目标，可以是任何形式的字面量，只要是能无歧义的定位到目标就好，就好比在班级中，老师可以用张三来代表你，也可以用你的学号来代表你，但无论任何方式这些都只是一个代号（符号），这个代号指向你（符号引用）
- 直接引用：直接引用是可以指向目标的指针、相对偏移量或者是一个能直接或间接定位到目标的句柄。和虚拟机实现的内存有关，不同的虚拟机直接引用一般不同。

解析动作主要针对**类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符**7类符号引用进行。

**5、初始化**

​		这是**类加载机制的最后一步**，在这个阶段，java程序代码才开始真正执行。我们知道，在准备阶段已经为类变量赋过一次值。在初始化阶端，程序员可以根据自己的需求来赋值了。

​		一句话描述这个阶段就是执行类构造器**< clinit >()方法**的过程。

​		在初始化阶段，主要为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：

- ①声明类变量是指定初始值

- ②使用静态代码块为类变量指定初始值

注意以下几种情况不会执行类初始化：

- 1、通过**子类引用父类的静态字段**，只会触发父类的初始化，而不会触发子类的初始化。
- 2、定义**对象数组**，不会触发该类的初始化。
- 3、**常量**在编译期间会存入**调用类的常量池**中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。
- 4、通过**类名获取Class 对象**，不会触发类的初始化。
- 5、通过**Class.forName 加载指定类**时，如果指定参数initialize 为false 时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。
- 6、**通过ClassLoader 默认的loadClass 方法**，也不会触发初始化动作。

JVM初始化步骤

- 1、假如这个类还没有被加载和连接，则程序先加载并连接该类
- 2、假如该类的直接父类还没有被初始化，则先初始化其直接父类
- 3、假如类中有初始化语句，则系统依次执行这些初始化语句

类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种：

- 创建类的实例，也就是new的方式
- 访问某个类或接口的静态变量，或者对该静态变量赋值
- 调用类的静态方法
- 反射（如 Class.forName(“com.shengsiyuan.Test”)）
- 初始化某个类的子类，则其父类也会被初始化
- Java虚拟机启动时被标明为启动类的类（ JavaTest），直接使用 java.exe命令来运行某个主类

​      好了，到目前为止就是类加载机制的整个过程，但是还有一个重要的概念，那就是类加载器。在加载阶段其实我们提到过类加载器，说是在后面详细说，在这就好好地介绍一下类加载器。



**三、类加载器**

虚拟机设计团队把加载动作放到**JVM外部**实现，以便让应用程序决定如何获取所需的类。

**1、Java语言系统自带有三个类加载器:**

- 1、==**Bootstrap ClassLoader ：**==最顶层的加载类，主要加载核心类库，也就是我们环境变量下面%JRE_HOME%\lib下的rt.jar、resources.jar、charsets.jar和class等。另外需要注意的是可以通过启动jvm时指定-Xbootclasspath和路径来改变Bootstrap ClassLoader的加载目录。比如java -Xbootclasspath/a:path被指定的文件追加到默认的bootstrap路径中。我们可以打开我的电脑，在上面的目录下查看，看看这些jar包是不是存在于这个目录。
- 2、==**Extention ClassLoader**==：扩展的类加载器，加载目录%JRE_HOME%\lib\ext目录下的jar包和class文件。还可以加载-D java.ext.dirs选项指定的目录。
- 3、==**Appclass Loader**==：也称为SystemAppClass。 加载当前应用的classpath的所有类

​      我们看到java为我们提供了三个类加载器，应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。这三种类加载器的加载顺序是什么呢？

==**Bootstrap ClassLoader      >       Extention ClassLoader     >         Appclass Loader**==

一张图来看一下他们的层次关系

![img](https://pics1.baidu.com/feed/eaf81a4c510fd9f950e68758c03f2f2e2834a422.jpeg?token=df76c19dfd873594da9128e32f646978&s=49A01D7213AFC0E840F5BDC70000C0A1)

代码验证一下：

![img](https://pics4.baidu.com/feed/8694a4c27d1ed21b63619c17497c26c050da3fab.jpeg?token=4829b4d609a17d47dc9e7b0f43dbd0ac&s=4C008D1A1D98C0C810E805DB0200D0B1)

从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C\C++语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。

**2、类加载的三种方式**

认识了这三种类加载器，接下来我们看看类加载的三种方式。

- （1）通过命令行启动应用时由JVM初始化加载**含有main()方法的主类**。

- （2）通过**Class.forName()**方法**动态加载**，会默认执行初始化块（static{}），但是Class.forName(name,initialize,loader)中的initialze可指定是否要执行初始化块。

- （3）通过**ClassLoader.loadClass()**方法**动态加载**，不会执行初始化块。



==**3、双亲委派原则**==

​		他的工作流程是： 当一个类加载器收到类加载任务，会先交给其**父类加载器**去完成，**依次递归**，因此最终加载任务都会传递到**顶层的启动类加载器**，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。

​		这个理解起来就简单了，比如说，另外一个人给小费，自己不会先去直接拿来塞自己钱包，我们先把钱给领导，领导再给领导，一直到公司老板，老板不想要了，再一级一级往下分。老板要是要这个钱，下面的领导和自己就一分钱没有了。（例子不好，理解就好）

​		采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象。双亲委派原则归纳一下就是：

- **1、可以避免重复加载**，父类已经加载了，子类就不需要再次加载
- **2、更加安全**，很好的**解决了各个类加载器的基础类的统一问题**，如果不使用该种方式，那么用户可以随意定义类加载器来加载核心api，会带来相关隐患。

**4、自定义类加载器**

​		在这一部分第一小节中，我们提到了java系统为我们提供的三种类加载器，还给出了他们的层次关系图，最下面就是自定义类加载器，那么我们如何自己定义类加载器呢？这主要有两种方式

- （1）遵守双亲委派模型：继承ClassLoader，重写findClass()方法。
- （2）破坏双亲委派模型：继承ClassLoader,重写loadClass()方法。 通常我们推荐采用第一种方法自定义类加载器，最大程度上的遵守双亲委派模型。

我们看一下实现步骤

- （1）创建一个类继承ClassLoader抽象类

- （2）重写findClass()方法

- （3）在findClass()方法中调用defineClass()













